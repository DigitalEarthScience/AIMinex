{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea8080c0-fabf-49cc-bae8-622a0761cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed!\n",
      "Found 46 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "Class Indices: {'Galena': 0, 'Goethite': 1, 'Pyrite': 2}\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:16:58.669616: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 6s 4s/step - loss: 3.0128 - accuracy: 0.2609 - val_loss: 2.2424 - val_accuracy: 0.4000\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:17:04.352476: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_12 in the registry.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 255, in __call__\n",
      "    raise ValueError(f\"Could not find callback with key={token} in the \"\n",
      "\n",
      "ValueError: Could not find callback with key=pyfunc_12 in the registry.\n",
      "\n",
      "\n",
      "2024-08-22 16:17:04.352515: W tensorflow/core/kernels/data/generator_dataset_op.cc:108] Error occurred when finalizing GeneratorDataset iterator: INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_12 in the registry.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 255, in __call__\n",
      "    raise ValueError(f\"Could not find callback with key={token} in the \"\n",
      "\n",
      "ValueError: Could not find callback with key=pyfunc_12 in the registry.\n",
      "\n",
      "\n",
      "\t [[{{node EagerPyFunc}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 5s/step - loss: 1.9091 - accuracy: 0.4130 - val_loss: 1.1497 - val_accuracy: 0.4000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 6s 5s/step - loss: 1.2345 - accuracy: 0.3043 - val_loss: 1.3856 - val_accuracy: 0.2667\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:17:15.897443: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_43 in the registry.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 255, in __call__\n",
      "    raise ValueError(f\"Could not find callback with key={token} in the \"\n",
      "\n",
      "ValueError: Could not find callback with key=pyfunc_43 in the registry.\n",
      "\n",
      "\n",
      "2024-08-22 16:17:15.897499: W tensorflow/core/kernels/data/generator_dataset_op.cc:108] Error occurred when finalizing GeneratorDataset iterator: INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_43 in the registry.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 255, in __call__\n",
      "    raise ValueError(f\"Could not find callback with key={token} in the \"\n",
      "\n",
      "ValueError: Could not find callback with key=pyfunc_43 in the registry.\n",
      "\n",
      "\n",
      "\t [[{{node EagerPyFunc}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 6s 5s/step - loss: 1.2532 - accuracy: 0.2609 - val_loss: 1.0618 - val_accuracy: 0.4000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 6s 3s/step - loss: 1.1493 - accuracy: 0.5217 - val_loss: 1.1843 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 1s 538ms/step\n",
      "1/1 [==============================] - 1s 537ms/step\n",
      "Dataset split completed!\n",
      "Found 51 images belonging to 3 classes.\n",
      "Found 20 images belonging to 3 classes.\n",
      "Class Indices: {'Galena': 0, 'Goethite': 1, 'Pyrite': 2}\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 6s 4s/step - loss: 3.7045 - accuracy: 0.3922 - val_loss: 2.0283 - val_accuracy: 0.4000\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:19:58.302226: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_92 in the registry.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 255, in __call__\n",
      "    raise ValueError(f\"Could not find callback with key={token} in the \"\n",
      "\n",
      "ValueError: Could not find callback with key=pyfunc_92 in the registry.\n",
      "\n",
      "\n",
      "2024-08-22 16:19:58.302273: W tensorflow/core/kernels/data/generator_dataset_op.cc:108] Error occurred when finalizing GeneratorDataset iterator: INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_92 in the registry.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 255, in __call__\n",
      "    raise ValueError(f\"Could not find callback with key={token} in the \"\n",
      "\n",
      "ValueError: Could not find callback with key=pyfunc_92 in the registry.\n",
      "\n",
      "\n",
      "\t [[{{node EagerPyFunc}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 6s/step - loss: 2.3583 - accuracy: 0.3137 - val_loss: 1.7532 - val_accuracy: 0.2500\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 7s 4s/step - loss: 1.8277 - accuracy: 0.2745 - val_loss: 1.4668 - val_accuracy: 0.2500\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 7s 4s/step - loss: 1.3591 - accuracy: 0.2745 - val_loss: 1.2133 - val_accuracy: 0.4000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 7s 5s/step - loss: 1.2899 - accuracy: 0.4118 - val_loss: 1.2464 - val_accuracy: 0.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:20:27.184668: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_147 in the registry.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 255, in __call__\n",
      "    raise ValueError(f\"Could not find callback with key={token} in the \"\n",
      "\n",
      "ValueError: Could not find callback with key=pyfunc_147 in the registry.\n",
      "\n",
      "\n",
      "2024-08-22 16:20:27.184791: W tensorflow/core/kernels/data/generator_dataset_op.cc:108] Error occurred when finalizing GeneratorDataset iterator: INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_147 in the registry.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 255, in __call__\n",
      "    raise ValueError(f\"Could not find callback with key={token} in the \"\n",
      "\n",
      "ValueError: Could not find callback with key=pyfunc_147 in the registry.\n",
      "\n",
      "\n",
      "\t [[{{node EagerPyFunc}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 518ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "\n",
    "# Enable Debug Mode for tf.data\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "# Optionally force TensorFlow to run on the CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "def split_dataset(source_dir, train_dir, val_dir, split_ratio=0.9):\n",
    "    \"\"\"Splits the dataset into training and validation sets.\"\"\"\n",
    "    for class_name in os.listdir(source_dir):\n",
    "        class_path = os.path.join(source_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            images = os.listdir(class_path)\n",
    "            random.shuffle(images)\n",
    "            split_point = int(len(images) * split_ratio)\n",
    "\n",
    "            train_images = images[:split_point]\n",
    "            val_images = images[split_point:]\n",
    "\n",
    "            # Create directories for train and validation sets\n",
    "            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "            os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
    "\n",
    "            # Move the images to the respective directories\n",
    "            for img in train_images:\n",
    "                shutil.copy(os.path.join(class_path, img), os.path.join(train_dir, class_name, img))\n",
    "\n",
    "            for img in val_images:\n",
    "                shutil.copy(os.path.join(class_path, img), os.path.join(val_dir, class_name, img))\n",
    "\n",
    "    print(\"Dataset split completed!\")\n",
    "\n",
    "\n",
    "# Disable multi-threading in the data generator\n",
    "def start_training():\n",
    "    global class_indices\n",
    "\n",
    "    source_dir = 'deeplearning images'\n",
    "    train_dir = 'split_data/train'\n",
    "    val_dir = 'split_data/validation'\n",
    "\n",
    "    # Split the dataset if necessary\n",
    "    split_dataset(source_dir, train_dir, val_dir)\n",
    "\n",
    "    # Define the data augmentation and preprocessing (now only using rescale)\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "    validation_generator = val_datagen.flow_from_directory(val_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "    # Store class indices globally\n",
    "    class_indices = train_generator.class_indices\n",
    "    print(\"Class Indices:\", class_indices)\n",
    "\n",
    "    # Load the ResNet50 model and fine-tune it\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top of the base model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_generator, validation_data=validation_generator, epochs=5, workers=1, use_multiprocessing=False)\n",
    "\n",
    "    # Save the model\n",
    "    model.save('best_model.h5')\n",
    "    messagebox.showinfo(\"Info\", \"Training completed!\")\n",
    "\n",
    "\n",
    "def upload_and_classify_image():\n",
    "    global class_indices  # Access the global class indices\n",
    "\n",
    "    file_path = filedialog.askopenfilename(title=\"Select Image\", filetypes=[(\"Image files\", \"*.jpg *.png *.jpeg\")])\n",
    "    if file_path:\n",
    "        img = Image.open(file_path)\n",
    "        img = img.resize((224, 224))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        # Preprocess the image\n",
    "        img_array = keras_image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array /= 255.0\n",
    "\n",
    "        # Load the model and make a prediction\n",
    "        model = load_model('best_model.h5')\n",
    "        predictions = model.predict(img_array)\n",
    "        predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "        # Get the class label using the stored class indices\n",
    "        if class_indices:\n",
    "            class_labels = {v: k for k, v in class_indices.items()}\n",
    "            class_name = class_labels.get(predicted_class, \"Unknown\")\n",
    "        else:\n",
    "            class_name = \"Unknown\"\n",
    "\n",
    "        result_label.config(text=f\"Predicted Class: {class_name}\")\n",
    "    else:\n",
    "        messagebox.showwarning(\"Warning\", \"No file selected!\")\n",
    "\n",
    "\n",
    "# Tkinter application setup\n",
    "app = tk.Tk()\n",
    "app.title(\"Image Classification App\")\n",
    "\n",
    "# Image display area\n",
    "image_label = tk.Label(app)\n",
    "image_label.pack(pady=20)\n",
    "\n",
    "# Button to start training\n",
    "train_button = tk.Button(app, text=\"Start Training\", command=start_training)\n",
    "train_button.pack(pady=20)\n",
    "\n",
    "# Button to upload and classify image\n",
    "upload_button = tk.Button(app, text=\"Upload and Classify Image\", command=upload_and_classify_image)\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "# Label to show the classification result\n",
    "result_label = tk.Label(app, text=\"\")\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "# Run the app\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ec04cd-8b39-4857-a2b2-c42bb16a3bf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m start_training\u001b[38;5;241m.\u001b[39mbase_model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_training' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3592135-d10f-43bd-89af-8b6a06a002df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f319f-7c66-45db-b7a2-36bc7b7d6920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
