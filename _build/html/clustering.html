
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Types of Clustering Methods &#8212; MineralAI 0.0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Debugging" href="debugging.html" />
    <link rel="prev" title="PCA vs KernelPCA" href="pca.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="types-of-clustering-methods">
<h1>Types of Clustering Methods<a class="headerlink" href="#types-of-clustering-methods" title="Permalink to this heading">¶</a></h1>
<div class="line-block">
<div class="line">K-means Clustering</div>
<div class="line">K-means clustering organizes a dataset into k clusters by using the nearest means. K-means clustering starts by randomly initializing k-cluster centroids, then the data points are assigned to the closest cluster centroid, and the centroids of all clusters are recalculated based on the mean of the assigned points. Two steps are iteratively performed until the changes to the centroids become insignificant or a limit of iterations is reached. K-means is well suited for large datasets, but it is possible that it will be frozen at a local minimum.</div>
</div>
<div class="line-block">
<div class="line">Hierarchical Clustering</div>
<div class="line">Hierarchical clustering builds a dendrogram to represent the tendency to concentrate data points gradually. There are two main types: agglomerative (bottom-up) and divisive (top-down). In the agglomerative approach used in the MineralAI program, for every data point, a new cluster is created (that means, each data point is a cluster), and clusters are merged iteratively until the tree ends. This method is capable of capturing hierarchies, but it is highly computationally expensive for big datasets.</div>
</div>
<div class="line-block">
<div class="line">DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</div>
<div class="line">DBSCAN is a clustering method based on density group data points according to the density area of the data points. Its clusters are areas of high densities, separated by regions of low densities; thus, it can find clusters of arbitrary shape and handle noise (outliers) efficiently. The algorithm requires two parameters: the radius ϵepsilonϵ to define the neighbourhood of a point and the minimum number of points required to form a dense region. It does not require specifying the number of clusters in advance.</div>
</div>
<div class="line-block">
<div class="line">Mean Shift Clustering</div>
<div class="line">Mean Shift clustering is a non-parametric method that searches for dense regions in the feature space. It works by iteratively shifting each data point towards the mode (highest density point) within a defined window until convergence. The resulting clusters are areas where the points converge. This method can automatically detect the number of clusters and is suitable for arbitrary-shaped clusters but can be computationally intensive for large datasets.</div>
</div>
<div class="line-block">
<div class="line">Spectral Clustering</div>
<div class="line">Spectral clustering uses the eigenvalues of a similarity matrix to reduce the dimensionality of the data before applying a clustering method like K-means. It is effective for detecting non-convex clusters and clusters connected by complex relationships. The method involves constructing a similarity graph, computing the graph’s Laplacian matrix, and then using its eigenvectors for clustering.</div>
</div>
<div class="line-block">
<div class="line">Gaussian Mixture Models (GMM)</div>
<div class="line">The Gaussian mixture model is a soft clustering technique to determine the probability that a given data point belongs to a cluster. It is a probabilistic model that assumes the data is generated from a mixture of several Gaussian distributions with unknown parameters. Each cluster is represented by a Gaussian distribution, and the model estimates the parameters using the Expectation-Maximization (EM) algorithm. GMM can handle clusters with different shapes and sizes but requires specifying the number of components (clusters).</div>
</div>
<div class="line-block">
<div class="line">Affinity Propagation</div>
<div class="line">Affinity Propagation clustering does not require specifying the number of clusters beforehand. Instead, it identifies a set of representative points (exemplars) by iteratively passing messages between data points. These messages reflect the suitability of points and their preference to be exemplars. The method is effective for detecting clusters of various shapes and sizes but can be computationally heavy.</div>
</div>
<div class="line-block">
<div class="line">BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies)</div>
<div class="line">BIRCH is a hierarchical clustering method designed for very large datasets. It clusters multi-dimensional metric data points to create a clustering feature tree (CF tree) that summarizes the dataset. The algorithm uses these features to form clusters by iteratively refining the tree and clustering the leaf nodes. BIRCH is efficient and scalable, handling large datasets well, but it may not perform as effectively on datasets with clusters of varying densities.</div>
</div>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">MineralAI</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="step_guide.html">Program Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_guide.html">Functions and Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="new_content.html">Setting Up Excel Spreadsheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="Using_Navigation_Bar.html">Using Navigation Bar</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="saving_figure.html">How to Save High-Quality Figures</a></li>
<li class="toctree-l1"><a class="reference internal" href="yellowbrick.html">What is KElbowVisualizer?</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_excel.html">How to Save Data into Excel File</a></li>
<li class="toctree-l1"><a class="reference internal" href="pca.html">PCA vs KernelPCA</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Types of Clustering Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugging.html">Debugging</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="pca.html" title="previous chapter">PCA vs KernelPCA</a></li>
      <li>Next: <a href="debugging.html" title="next chapter">Debugging</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2024, Hom Nath Gharti, Tiger Fan.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.0.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/clustering.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>